{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "mins = 60\n",
    "\n",
    "from hmmlearn import hmm\n",
    "\n",
    "import nilmtk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import warnings\n",
    "import sys\n",
    "sys.path.append(\"../code/\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "from nilmtk import *\n",
    "import os\n",
    "import nilmtk\n",
    "\n",
    "metadata_df = pd.read_csv(\"./metadata.csv\",index_col=0)\n",
    "feeds = {'use':'aggregate',\n",
    "        'air1':'hvac',\n",
    "         'clotheswasher1':'wm',\n",
    "         'dishwasher1':'dw',\n",
    "         'microwave1':'mw',\n",
    "         'refrigerator1':'fridge',\n",
    "         'oven1':'oven',\n",
    "        }\n",
    "\n",
    "feed_r = {v:k for k, v in feeds.items()}\n",
    "city = 'Austin'\n",
    "year = 2015\n",
    "\n",
    "\n",
    "st = pd.HDFStore(os.path.expanduser(\"~/all.h5\"), mode='r')\n",
    "\n",
    "city_data = metadata_df[metadata_df['city'] == city]\n",
    "city_homes = city_data.index.values.astype('int')\n",
    "\n",
    "from common import APPLIANCES_ORDER\n",
    "\n",
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hvac training\n",
      "Length of o (385,)\n",
      "Means for hvac are\n",
      "[[  514.80215183]\n",
      " [   12.62050204]\n",
      " [ 1639.6020198 ]]\n",
      "fridge training\n",
      "Length of o (318,)\n",
      "Means for fridge are\n",
      "[[  53.08612528]\n",
      " [ 205.62985773]\n",
      " [ 105.05012415]]\n",
      "mw training\n",
      "Length of o (217,)\n",
      "Means for mw are\n",
      "[[   2.8869722 ]\n",
      " [  33.22728033]\n",
      " [ 120.46751662]]\n",
      "dw training\n",
      "Length of o (289,)\n",
      "Means for dw are\n",
      "[[  3.86828540e-102]\n",
      " [  4.67467286e+002]\n",
      " [  1.72742147e+001]]\n",
      "wm training\n",
      "Length of o (223,)\n",
      "Means for wm are\n",
      "[[   0.        ]\n",
      " [ 100.18015886]\n",
      " [   9.30022173]]\n",
      "oven training\n",
      "Length of o (125,)\n",
      "Means for oven are\n",
      "[[   8.85220768]\n",
      " [   2.19140812]\n",
      " [ 310.1776985 ]]\n"
     ]
    }
   ],
   "source": [
    "for appliance in APPLIANCES_ORDER[1:]:\n",
    "    print(appliance, \"training\")\n",
    "    o = []\n",
    "    for hn, home in enumerate(city_homes[:]):\n",
    "        #print(home, hn)\n",
    "\n",
    "        \n",
    "        try:\n",
    "            dft = st['/%d' %home]['%s' %year][feed_r[appliance]].iloc[3600:4080]\n",
    "            appl_power = dft.dropna().values.reshape(-1,1)\n",
    "            activation = (dft>10).sum()*1.0/len(dft)\n",
    "            if appliance in [\"wm\",\"dw\",\"oven\",\"mw\"]:\n",
    "                if len(appl_power)>10:\n",
    "                    o.append(appl_power)\n",
    "\n",
    "            else:\n",
    "                if activation>0.08:\n",
    "                    o.append(appl_power)\n",
    "        except :\n",
    "            pass\n",
    "\n",
    "    if len(o)>1:\n",
    "        o = np.array(o)\n",
    "        print(\"Length of o\", o.shape)\n",
    "        mod = hmm.GaussianHMM(3, \"full\")\n",
    "        mod.fit(o)\n",
    "        models[appliance] = mod\n",
    "        print(\"Means for %s are\" %appliance)\n",
    "        print(mod.means_)\n",
    "    else:\n",
    "        print(\"Not enough samples for %s\" %appliance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In[8]:\n",
    "\n",
    "from nilmtk.disaggregate.fhmm_exact import sort_learnt_parameters\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "new_learnt_models = OrderedDict()\n",
    "for appliance, appliance_model in models.items():\n",
    "    startprob, means, covars, transmat = sort_learnt_parameters(\n",
    "                    appliance_model.startprob_, appliance_model.means_,\n",
    "                    appliance_model.covars_, appliance_model.transmat_)\n",
    "    new_learnt_models[appliance] = hmm.GaussianHMM(\n",
    "                startprob.size, \"full\", startprob, transmat)\n",
    "    new_learnt_models[appliance].means_ = means\n",
    "    new_learnt_models[appliance].covars_ = covars\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "from nilmtk.disaggregate.fhmm_exact import create_combined_hmm\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "learnt_model_combined = create_combined_hmm(new_learnt_models)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "from nilmtk.disaggregate.fhmm_exact import FHMM\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "f = FHMM()\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "f.model = learnt_model_combined\n",
    "f.individual = new_learnt_models\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "pickle.dump(f, open( \"../fhmm_model_all_%d.p\" %mins, \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensor = np.load('../1H-input.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 7, 336)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_all, valid_homes = create_subset_dataset(tensor)\n",
    "t_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_subset_dataset(tensor):\n",
    "    t_subset = tensor[:, :, 180:194, :]\n",
    "    all_indices = np.array(list(range(320)))\n",
    "    for i in range(1, 7):\n",
    "        valid_homes = pd.DataFrame(t_subset[:, i, :].reshape(320, 14*24)).dropna().index\n",
    "        all_indices = np.intersect1d(all_indices, valid_homes)\n",
    "    t_subset = t_subset[all_indices, :, :, :].reshape(52, 7, 14*24)\n",
    "    \n",
    "    # Create artificial aggregate\n",
    "    t_subset[:, 0, :] = 0.0\n",
    "    for i in range(1, 7):\n",
    "        t_subset[:, 0, :] = t_subset[:, 0, :] + t_subset[:, i, :]\n",
    "    # t_subset is of shape (#home, appliance, days*hours)\n",
    "    return t_subset, all_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_agg = t_all[:30, 0, :].reshape(30*14, 24)\n",
    "train_appliance = t_all[:30, 1:, :].reshape(30*14, 6*24)\n",
    "\n",
    "train_hvac = t_all[:30, 1, :].reshape(30*14, 24)\n",
    "train_fridge = t_all[:30, 2, :].reshape(30*14, 24)\n",
    "train_mw = t_all[:30, 3, :].reshape(30*14, 24)\n",
    "train_dw = t_all[:30, 4, :].reshape(30*14, 24)\n",
    "train_wm = t_all[:30, 5, :].reshape(30*14, 24)\n",
    "train_oven = t_all[:30, 6, :].reshape(30*14, 24)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_agg_new = train_hvac + train_fridge\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_hvac = t_all[30:, 1, :].reshape(22*14, 24)\n",
    "test_fridge = t_all[30:, 2, :].reshape(22*14, 24)\n",
    "test_mw = t_all[30:, 3, :].reshape(22*14, 24)\n",
    "test_dw = t_all[30:, 4, :].reshape(22*14, 24)\n",
    "test_wm = t_all[30:, 5, :].reshape(22*14, 24)\n",
    "test_oven = t_all[30:, 6, :].reshape(22*14, 24)\n",
    "test_appliance = t_all[30:, 1:, :].reshape(22*14, 6*24)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_agg = t_all[30:, 0, :].reshape(22*14, 24)\n",
    "test_agg_new = test_hvac + test_fridge\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from common import APPLIANCES_ORDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(420, 24)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_hvac.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hvac training\n",
      "Means for hvac are\n",
      "[[  857.78000675]\n",
      " [  134.12083446]\n",
      " [ 1982.11966036]]\n",
      "fridge training\n",
      "Means for fridge are\n",
      "[[  65.60073032]\n",
      " [ 139.81886167]\n",
      " [  82.2790635 ]]\n",
      "mw training\n",
      "Means for mw are\n",
      "[[   2.27637744]\n",
      " [ 107.08210731]\n",
      " [  19.46393628]]\n",
      "dw training\n",
      "Means for dw are\n",
      "[[  6.45316426e-06]\n",
      " [  5.20760204e+02]\n",
      " [  2.09764943e+01]]\n",
      "wm training\n",
      "Means for wm are\n",
      "[[   0.        ]\n",
      " [ 106.51820273]\n",
      " [  10.2084481 ]]\n",
      "oven training\n",
      "Means for oven are\n",
      "[[   1.73995153]\n",
      " [   7.87050492]\n",
      " [ 556.4387012 ]]\n",
      "Not enough samples for oven\n"
     ]
    }
   ],
   "source": [
    "for appliance in APPLIANCES_ORDER[1:]:\n",
    "    print(appliance, \"training\")\n",
    "    train_appliance = t_all[:30, APPLIANCES_ORDER.index(appliance), :].reshape(30*14, 24)\n",
    "    \n",
    "    mod = hmm.GaussianHMM(3, \"full\")\n",
    "    mod.fit(train_appliance.reshape(-1, 420, 1))\n",
    "    models[appliance] = mod\n",
    "    print(\"Means for %s are\" %appliance)\n",
    "    print(mod.means_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nilmtk.disaggregate.fhmm_exact import sort_learnt_parameters\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "new_learnt_models = OrderedDict()\n",
    "for appliance, appliance_model in models.items():\n",
    "    startprob, means, covars, transmat = sort_learnt_parameters(\n",
    "                    appliance_model.startprob_, appliance_model.means_,\n",
    "                    appliance_model.covars_, appliance_model.transmat_)\n",
    "    new_learnt_models[appliance] = hmm.GaussianHMM(\n",
    "                startprob.size, \"full\", startprob, transmat)\n",
    "    new_learnt_models[appliance].means_ = means\n",
    "    new_learnt_models[appliance].covars_ = covars\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "from nilmtk.disaggregate.fhmm_exact import create_combined_hmm\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "learnt_model_combined = create_combined_hmm(new_learnt_models)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "from nilmtk.disaggregate.fhmm_exact import FHMM\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "f = FHMM()\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "f.model = learnt_model_combined\n",
    "f.individual = new_learnt_models\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "pickle.dump(f, open( \"../fhmm_model_all_%d.p\" %mins, \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      858.000000\n",
       "1      858.000000\n",
       "2      134.000000\n",
       "3      134.000000\n",
       "4      134.000000\n",
       "5      132.799999\n",
       "6       70.916664\n",
       "7      134.000000\n",
       "8      858.000000\n",
       "9      134.000000\n",
       "10     134.000000\n",
       "11     858.000000\n",
       "12     858.000000\n",
       "13     858.000000\n",
       "14     858.000000\n",
       "15     858.000000\n",
       "16    1982.000000\n",
       "17    1982.000000\n",
       "18    1982.000000\n",
       "19    1982.000000\n",
       "20     858.000000\n",
       "21     858.000000\n",
       "22    1982.000000\n",
       "23     858.000000\n",
       "Name: hvac, dtype: float64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p['hvac'][p['hvac']>d] = d[[p['hvac']>d]]\n",
    "p['hvac']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n"
     ]
    }
   ],
   "source": [
    "pred_fhmm = []\n",
    "pred = {}\n",
    "for appliance in APPLIANCES_ORDER[1:]:\n",
    "    pred[appliance] = []\n",
    "for i, d in enumerate(test_agg[:]):\n",
    "    print(i)\n",
    "    p = f.disaggregate_chunk(pd.DataFrame(d))\n",
    "    p['hvac'][p['hvac']>d] = d[[p['hvac']>d]]\n",
    "\n",
    "\n",
    "    for appliance in p.columns:\n",
    "        pred[appliance].append(p[appliance].values)\n",
    "for appliance in APPLIANCES_ORDER[1:]:\n",
    "    pred[appliance] = np.array(pred[appliance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hvac 433.323076353\n",
      "fridge 42.0302172858\n",
      "mw 40.9481669386\n",
      "dw 169.639290198\n",
      "wm 43.5151041613\n",
      "oven 171.871076865\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "for appliance in APPLIANCES_ORDER[1:]:\n",
    "        print(appliance, mean_absolute_error(pred[appliance],  t_all[30:, APPLIANCES_ORDER.index(appliance), :].reshape(22*14, 24)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
